{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q_c61NjnfSf",
        "outputId": "760324ea-fc44-48be-879e-a7c9eb05df62"
      },
      "outputs": [],
      "source": [
        "%pip install feedparser\n",
        "%pip install --upgrade openai\n",
        "%pip install elevenlabs\n",
        "%pip install python-telegram-bot --upgrade\n",
        "%pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOgw61lRFhx7"
      },
      "outputs": [],
      "source": [
        "EPISODE_ID = 1 # Enter episode number for ID \n",
        "EPISODE_NAME = f\"Pawdcast Episode {EPISODE_ID}\"\n",
        "EPISODE_TITLE = f\"Pawdcast Episode {EPISODE_ID}.mp3\"\n",
        "EPISODE_TITLE_FULL = f\"Pawdcast Episode {EPISODE_ID} Full.mp3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qED2Sg3WnfSh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import feedparser\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import uuid\n",
        "from elevenlabs import VoiceSettings\n",
        "from elevenlabs.client import ElevenLabs\n",
        "import moviepy.editor as mpe\n",
        "from telegram import Bot, InputFile\n",
        "import logging\n",
        "import nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCsH6NxTnfSi"
      },
      "outputs": [],
      "source": [
        "FEED_URL = '.....' # Input RSS feed from URL\n",
        "OPENAI_API_KEY = '......' # Enter your API key for OpenAI\n",
        "ELEVENLABS_API_KEY = '......' # Enter your API key for ElevenLabs, you need to choose and add a voice to be used in your Voice Library in ElevenLabs.\n",
        "ELEVENLABS_VOICE_ID = '.....' # Your choice of the voice with Voice ID from ElevenLabs\n",
        "\n",
        "TOKEN = '.....' # Telegram bot token\n",
        "CHAT_ID = '....' # Telegram chat id\n",
        "MESSAGE_THREAD_ID = 1 # Telegram message thread id, you can find it on the telegram topic and taking the number after / in the share link\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaWWmpaZnfSi"
      },
      "outputs": [],
      "source": [
        "d = feedparser.parse(FEED_URL)\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "el_client = ElevenLabs(\n",
        "    api_key=ELEVENLABS_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TicyyCcp8Ny3",
        "outputId": "94fb4aaa-a3d4-4c52-e69c-d60044bd264d"
      },
      "outputs": [],
      "source": [
        "d.entries[0].title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQT8z503nfSi"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a cat, who is hosting an podcast called Pawdcast for AI news, skilled in your cat things and presenting the current news in funny and engaging ways while still providing the important information.\"},\n",
        "    {\"role\": \"user\", \"content\": d.entries[0].content[0].value}\n",
        "  ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTxWpvpLnfSj",
        "outputId": "df50a01d-b65f-4f98-97f6-68100fa40d3c"
      },
      "outputs": [],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRlSIYMEnfSk"
      },
      "outputs": [],
      "source": [
        "def text_to_speech_file(text: str) -> str:\n",
        "    # Calling the text_to_speech conversion API with detailed parameters\n",
        "    response = el_client.text_to_speech.convert(\n",
        "        voice_id=ELEVENLABS_VOICE_ID, \n",
        "        optimize_streaming_latency=\"0\",\n",
        "        output_format=\"mp3_22050_32\",\n",
        "        text=text,\n",
        "        model_id=\"eleven_turbo_v2\", # use the turbo model for low latency, for other languages use the `eleven_multilingual_v2`\n",
        "        voice_settings=VoiceSettings(\n",
        "            stability=0.33,\n",
        "            similarity_boost=0.59,\n",
        "            style=0.0,\n",
        "            use_speaker_boost=False,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Writing the audio to a file\n",
        "    with open(EPISODE_TITLE, \"wb\") as f:\n",
        "        for chunk in response:\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "    print(f\"{EPISODE_NAME}: A new audio file was saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTCOTmtOnfSk",
        "outputId": "7e142ddf-cc6c-4d50-8850-691013581653"
      },
      "outputs": [],
      "source": [
        "text_to_speech_file(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5MIQkKX3Dpz",
        "outputId": "9916a429-5b48-449e-9cf5-b488c7358cc8"
      },
      "outputs": [],
      "source": [
        "# Generate/find a intro music and put inside the same folder as the file\n",
        "\n",
        "# Load the two audio files\n",
        "meow_meow_meow = mpe.AudioFileClip(\"intro.mp3\") \n",
        "pawdcast_episode = mpe.AudioFileClip(EPISODE_TITLE)\n",
        "\n",
        "# Take the first 9.5 seconds of the meow meow meow song\n",
        "meow_meow_meow_intro = meow_meow_meow.subclip(0, 9.5)\n",
        "\n",
        "# Combine the intro with the Pawdcast episode\n",
        "combined_audio = mpe.concatenate_audioclips([meow_meow_meow_intro, pawdcast_episode])\n",
        "\n",
        "# Save the new file\n",
        "combined_audio.write_audiofile(EPISODE_TITLE_FULL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i5v4VnPFZ7Q"
      },
      "outputs": [],
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "async def post_pawdcast(bot):\n",
        "    text_message = \"Here's the latest AI Pawdcast episode! Enjoy and Meow out.\"\n",
        "\n",
        "    # Sending message\n",
        "    await bot.send_message(chat_id=CHAT_ID, text=text_message, message_thread_id=MESSAGE_THREAD_ID)\n",
        "    # Sending audio\n",
        "    with open(EPISODE_TITLE_FULL, 'rb') as audio_file:\n",
        "        await bot.send_audio(chat_id=CHAT_ID, audio=audio_file, title=EPISODE_NAME, message_thread_id=MESSAGE_THREAD_ID)\n",
        "\n",
        "async def main():\n",
        "    # Initialize the bot\n",
        "    bot = Bot(token=TOKEN)\n",
        "\n",
        "    # Post the pawdcast to the specified chat\n",
        "    await post_pawdcast(bot)\n",
        "\n",
        "# Run the main function using asyncio\n",
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prompt: use the existing conversation and send another message that says 'add clickable links using markdown to the relevant text in the script, only reply with the script'\n",
        "\n",
        "completion_script_links = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You get a newsletter with links and a script without. Add links to the relevant parts in the script using markdown. Only reply with the script.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"newsletter: {d.entries[0].content[0].value}, script: {completion.choices[0].message.content}\"}\n",
        "  ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def post_message(message_part):\n",
        "    bot = Bot(token=TOKEN)\n",
        "    await bot.send_message(chat_id=CHAT_ID, text=message_part, message_thread_id=MESSAGE_THREAD_ID, parse_mode='Markdown', disable_web_page_preview=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prompt: split message into multiple messages using splitlines and join so that each message is roughly the same size and no larger than 4096 characters\n",
        "message = completion_script_links.choices[0].message.content\n",
        "\n",
        "lines = message.splitlines()\n",
        "max_message_length = 4096\n",
        "messages = []\n",
        "current_message = \"\"\n",
        "\n",
        "for line in lines:\n",
        "    if len(current_message) + len(line) < max_message_length:\n",
        "        current_message += line + \"\\n\"\n",
        "    else:\n",
        "        messages.append(current_message)\n",
        "        current_message = line + \"\\n\"\n",
        "\n",
        "if current_message:\n",
        "    messages.append(current_message)\n",
        "\n",
        "# Print the messages\n",
        "for message in messages:\n",
        "    await post_message(message)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
